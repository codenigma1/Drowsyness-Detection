{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU availability\n",
    "print(\"Available GPUs:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation and preparation\n",
    "train_data_generator = ImageDataGenerator(rescale=1./255, rotation_range=0.2, shear_range=0.2, zoom_range=0.2, \n",
    "                                          width_shift_range=0.2, height_shift_range=0.2, validation_split=0.2,horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64524 images belonging to 2 classes.\n",
      "Found 16130 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Train and validation data\n",
    "train_data = train_data_generator.flow_from_directory(\n",
    "    'data/train',\n",
    "    target_size=(80, 80),  # Updated size for EfficientNetB0\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_data = train_data_generator.flow_from_directory(\n",
    "    'data/train',\n",
    "    target_size=(80, 80),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4244 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Test data preparation\n",
    "test_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_data = test_data_generator.flow_from_directory(\n",
    "    'data/test',\n",
    "    target_size=(80, 80),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights to handle class imbalance\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_data.classes),\n",
    "    y=train_data.classes\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(80, 80, 3))\n",
    "# Access the output of the base model\n",
    "head_model = base_model.output\n",
    "# Adding a fully connected layer of finetuning\n",
    "head_model = Flatten()(head_model)\n",
    "head_model = Dense(128, activation='relu')(head_model)\n",
    "head_model = Dropout(0.5)(head_model)\n",
    "head_model = Dense(64, activation='relu')(head_model)\n",
    "head_model = Dropout(0.5)(head_model)\n",
    "head_model = Dense(2, activation='softmax')(head_model)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=head_model)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model as best_model.h5\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='save_models/InceptionV3_best_model.h5',  # Save the best model as best_model.h5\n",
    "    monitor='val_loss',       # Monitor validation loss\n",
    "    verbose=3,                # Verbose output to show progress\n",
    "    save_best_only=True,      # Save only the best model (not every epoch)\n",
    "    save_weights_only=False   # Save the entire model, not just the weights\n",
    ")\n",
    "earlystop = EarlyStopping(monitor='val_loss', \n",
    "                          patience=7, \n",
    "                          verbose=3, \n",
    "                          restore_best_weights=True)\n",
    "\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
    "                                            patience=3, \n",
    "                                            verbose=3)\n",
    "\n",
    "callbacks = [checkpoint, earlystop, learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [checkpoint, earlystop, learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompile the model after unfreezing\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),  # Smaller learning rate for fine-tuning\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4031/4032 [============================>.] - ETA: 0s - loss: 0.4750 - accuracy: 0.7723\n",
      "Epoch 1: val_loss improved from inf to 0.32587, saving model to save_models\\InceptionV3_best_model.h5\n",
      "4032/4032 [==============================] - 156s 38ms/step - loss: 0.4749 - accuracy: 0.7724 - val_loss: 0.3259 - val_accuracy: 0.8493 - lr: 1.0000e-05\n",
      "Epoch 2/30\n",
      "4030/4032 [============================>.] - ETA: 0s - loss: 0.3070 - accuracy: 0.8765\n",
      "Epoch 2: val_loss improved from 0.32587 to 0.29441, saving model to save_models\\InceptionV3_best_model.h5\n",
      "4032/4032 [==============================] - 126s 31ms/step - loss: 0.3070 - accuracy: 0.8765 - val_loss: 0.2944 - val_accuracy: 0.8669 - lr: 1.0000e-05\n",
      "Epoch 3/30\n",
      "4031/4032 [============================>.] - ETA: 0s - loss: 0.2628 - accuracy: 0.8983\n",
      "Epoch 3: val_loss improved from 0.29441 to 0.27681, saving model to save_models\\InceptionV3_best_model.h5\n",
      "4032/4032 [==============================] - 182s 45ms/step - loss: 0.2628 - accuracy: 0.8984 - val_loss: 0.2768 - val_accuracy: 0.8769 - lr: 1.0000e-05\n",
      "Epoch 4/30\n",
      "4031/4032 [============================>.] - ETA: 0s - loss: 0.2450 - accuracy: 0.9052\n",
      "Epoch 4: val_loss improved from 0.27681 to 0.26291, saving model to save_models\\InceptionV3_best_model.h5\n",
      "4032/4032 [==============================] - 179s 44ms/step - loss: 0.2450 - accuracy: 0.9052 - val_loss: 0.2629 - val_accuracy: 0.8828 - lr: 1.0000e-05\n",
      "Epoch 5/30\n",
      "4030/4032 [============================>.] - ETA: 0s - loss: 0.2311 - accuracy: 0.9109\n",
      "Epoch 5: val_loss improved from 0.26291 to 0.25255, saving model to save_models\\InceptionV3_best_model.h5\n",
      "4032/4032 [==============================] - 83s 20ms/step - loss: 0.2311 - accuracy: 0.9110 - val_loss: 0.2526 - val_accuracy: 0.8926 - lr: 1.0000e-05\n",
      "Epoch 6/30\n",
      "4030/4032 [============================>.] - ETA: 0s - loss: 0.2189 - accuracy: 0.9162\n",
      "Epoch 6: val_loss improved from 0.25255 to 0.25065, saving model to save_models\\InceptionV3_best_model.h5\n",
      "4032/4032 [==============================] - 83s 21ms/step - loss: 0.2189 - accuracy: 0.9162 - val_loss: 0.2506 - val_accuracy: 0.8902 - lr: 1.0000e-05\n",
      "Epoch 7/30\n",
      "4032/4032 [==============================] - ETA: 0s - loss: 0.2142 - accuracy: 0.9184\n",
      "Epoch 7: val_loss improved from 0.25065 to 0.24510, saving model to save_models\\InceptionV3_best_model.h5\n",
      "4032/4032 [==============================] - 86s 21ms/step - loss: 0.2142 - accuracy: 0.9184 - val_loss: 0.2451 - val_accuracy: 0.8949 - lr: 1.0000e-05\n",
      "Epoch 8/30\n",
      "4032/4032 [==============================] - ETA: 0s - loss: 0.2058 - accuracy: 0.9207\n",
      "Epoch 8: val_loss improved from 0.24510 to 0.23517, saving model to save_models\\InceptionV3_best_model.h5\n",
      "4032/4032 [==============================] - 83s 21ms/step - loss: 0.2058 - accuracy: 0.9207 - val_loss: 0.2352 - val_accuracy: 0.9007 - lr: 1.0000e-05\n",
      "Epoch 9/30\n",
      "4029/4032 [============================>.] - ETA: 0s - loss: 0.2049 - accuracy: 0.9212\n",
      "Epoch 9: val_loss did not improve from 0.23517\n",
      "4032/4032 [==============================] - 83s 21ms/step - loss: 0.2048 - accuracy: 0.9212 - val_loss: 0.2380 - val_accuracy: 0.8951 - lr: 1.0000e-05\n",
      "Epoch 10/30\n",
      "4030/4032 [============================>.] - ETA: 0s - loss: 0.1972 - accuracy: 0.9240\n",
      "Epoch 10: val_loss improved from 0.23517 to 0.23305, saving model to save_models\\InceptionV3_best_model.h5\n",
      "4032/4032 [==============================] - 85s 21ms/step - loss: 0.1971 - accuracy: 0.9240 - val_loss: 0.2330 - val_accuracy: 0.8997 - lr: 1.0000e-05\n",
      "Epoch 11/30\n",
      "4030/4032 [============================>.] - ETA: 0s - loss: 0.1926 - accuracy: 0.9264\n",
      "Epoch 11: val_loss did not improve from 0.23305\n",
      "4032/4032 [==============================] - 85s 21ms/step - loss: 0.1926 - accuracy: 0.9264 - val_loss: 0.2371 - val_accuracy: 0.8965 - lr: 1.0000e-05\n",
      "Epoch 12/30\n",
      "4029/4032 [============================>.] - ETA: 0s - loss: 0.1877 - accuracy: 0.9287\n",
      "Epoch 12: val_loss did not improve from 0.23305\n",
      "4032/4032 [==============================] - 83s 21ms/step - loss: 0.1880 - accuracy: 0.9286 - val_loss: 0.2334 - val_accuracy: 0.9022 - lr: 1.0000e-05\n",
      "Epoch 13/30\n",
      "4029/4032 [============================>.] - ETA: 0s - loss: 0.1899 - accuracy: 0.9273\n",
      "Epoch 13: val_loss improved from 0.23305 to 0.23007, saving model to save_models\\InceptionV3_best_model.h5\n",
      "4032/4032 [==============================] - 83s 21ms/step - loss: 0.1899 - accuracy: 0.9273 - val_loss: 0.2301 - val_accuracy: 0.9000 - lr: 1.0000e-05\n",
      "Epoch 14/30\n",
      "4030/4032 [============================>.] - ETA: 0s - loss: 0.1854 - accuracy: 0.9296\n",
      "Epoch 14: val_loss did not improve from 0.23007\n",
      "4032/4032 [==============================] - 85s 21ms/step - loss: 0.1853 - accuracy: 0.9296 - val_loss: 0.2318 - val_accuracy: 0.9025 - lr: 1.0000e-05\n",
      "Epoch 15/30\n",
      "4032/4032 [==============================] - ETA: 0s - loss: 0.1857 - accuracy: 0.9301\n",
      "Epoch 15: val_loss did not improve from 0.23007\n",
      "4032/4032 [==============================] - 84s 21ms/step - loss: 0.1857 - accuracy: 0.9301 - val_loss: 0.2340 - val_accuracy: 0.9030 - lr: 1.0000e-05\n",
      "Epoch 16/30\n",
      "4032/4032 [==============================] - ETA: 0s - loss: 0.1803 - accuracy: 0.9323\n",
      "Epoch 16: val_loss improved from 0.23007 to 0.22696, saving model to save_models\\InceptionV3_best_model.h5\n",
      "4032/4032 [==============================] - 84s 21ms/step - loss: 0.1803 - accuracy: 0.9323 - val_loss: 0.2270 - val_accuracy: 0.9044 - lr: 1.0000e-05\n",
      "Epoch 17/30\n",
      "4032/4032 [==============================] - ETA: 0s - loss: 0.1814 - accuracy: 0.9319\n",
      "Epoch 17: val_loss improved from 0.22696 to 0.22162, saving model to save_models\\InceptionV3_best_model.h5\n",
      "4032/4032 [==============================] - 83s 21ms/step - loss: 0.1814 - accuracy: 0.9319 - val_loss: 0.2216 - val_accuracy: 0.9063 - lr: 1.0000e-05\n",
      "Epoch 18/30\n",
      "4030/4032 [============================>.] - ETA: 0s - loss: 0.1777 - accuracy: 0.9319\n",
      "Epoch 18: val_loss did not improve from 0.22162\n",
      "4032/4032 [==============================] - 84s 21ms/step - loss: 0.1778 - accuracy: 0.9319 - val_loss: 0.2242 - val_accuracy: 0.9056 - lr: 1.0000e-05\n",
      "Epoch 19/30\n",
      "4031/4032 [============================>.] - ETA: 0s - loss: 0.1746 - accuracy: 0.9332\n",
      "Epoch 19: val_loss did not improve from 0.22162\n",
      "4032/4032 [==============================] - 84s 21ms/step - loss: 0.1747 - accuracy: 0.9332 - val_loss: 0.2296 - val_accuracy: 0.9070 - lr: 1.0000e-05\n",
      "Epoch 20/30\n",
      "4032/4032 [==============================] - ETA: 0s - loss: 0.1710 - accuracy: 0.9354\n",
      "Epoch 20: val_loss did not improve from 0.22162\n",
      "\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "4032/4032 [==============================] - 86s 21ms/step - loss: 0.1710 - accuracy: 0.9354 - val_loss: 0.2287 - val_accuracy: 0.9041 - lr: 1.0000e-05\n",
      "Epoch 21/30\n",
      "4030/4032 [============================>.] - ETA: 0s - loss: 0.1714 - accuracy: 0.9351\n",
      "Epoch 21: val_loss did not improve from 0.22162\n",
      "4032/4032 [==============================] - 84s 21ms/step - loss: 0.1713 - accuracy: 0.9351 - val_loss: 0.2254 - val_accuracy: 0.9059 - lr: 1.0000e-06\n",
      "Epoch 22/30\n",
      "4029/4032 [============================>.] - ETA: 0s - loss: 0.1699 - accuracy: 0.9349\n",
      "Epoch 22: val_loss did not improve from 0.22162\n",
      "4032/4032 [==============================] - 84s 21ms/step - loss: 0.1700 - accuracy: 0.9349 - val_loss: 0.2271 - val_accuracy: 0.9062 - lr: 1.0000e-06\n",
      "Epoch 23/30\n",
      "4031/4032 [============================>.] - ETA: 0s - loss: 0.1713 - accuracy: 0.9361\n",
      "Epoch 23: val_loss did not improve from 0.22162\n",
      "\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "4032/4032 [==============================] - 91s 23ms/step - loss: 0.1713 - accuracy: 0.9361 - val_loss: 0.2300 - val_accuracy: 0.9062 - lr: 1.0000e-06\n",
      "Epoch 24/30\n",
      "4032/4032 [==============================] - ETA: 0s - loss: 0.1726 - accuracy: 0.9341\n",
      "Epoch 24: val_loss did not improve from 0.22162\n",
      "Restoring model weights from the end of the best epoch: 17.\n",
      "4032/4032 [==============================] - 86s 21ms/step - loss: 0.1726 - accuracy: 0.9341 - val_loss: 0.2302 - val_accuracy: 0.9048 - lr: 1.0000e-07\n",
      "Epoch 24: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    steps_per_epoch=train_data.samples // batch_size,\n",
    "    validation_data=val_data,\n",
    "    validation_steps=val_data.samples // batch_size,\n",
    "    callbacks=callbacks,\n",
    "    epochs=30,\n",
    "    class_weight=class_weights  # Handle class imbalance\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
